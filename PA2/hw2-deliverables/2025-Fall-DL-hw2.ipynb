{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework-2\n",
    "* CSCI-4931 : Deep Learning\n",
    "* Fall 2025\n",
    "* Instructor: Ashis Kumer Biswas\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Please assign your name, and declare collaborators (if any) to the variables below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_name = \" Shivam Pathak\"\n",
    "collaborators = \" None\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Little Background about the problem\n",
    "\n",
    "`Customer churn`` occurs when customers stop doing business with a company, also known as customer attrition. It is also referred to as loss of clients or customers.\n",
    "\n",
    "You are given sensitive information of 9,000 of an European Bank, EBQ. Your task is to build an Artificial Neural Network (ANN) based on the dataset such that later the ANN model can predict correctly who is going to leave next. This predictive analysis is vital for the EBQ bank to revise their business strategy towards customer retention. What do you think?\n",
    "\n",
    "Anyway, you are recruited by the bank to do the data science. And, the head of the bank only trusts heads, i.e., brains…. I mean neural networks for making any decisions. And luckily you were in Dr. B’s class and you know something(?) about the ANN that you could successfully convince the head of the bank during the interview. He has put a lot of faith in you. Now, can you solve his problem?\n",
    "\n",
    "Tasks:\n",
    "\n",
    "1. Please download the zip file, `hw2-deliverables.zip``. Unzip it in your workspace. Here below is the file hierarchy of \"hw2-deliverables/\" folder:\n",
    "\n",
    "```\n",
    "hw2-deliverables\n",
    "├── 2025-Fall-DL-hw2.ipynb\n",
    "├── dataset\n",
    "│   └── datasetX.csv\n",
    "├── figures\n",
    "│   ├── le.png\n",
    "│   ├── nn-1.png\n",
    "│   ├── nn-1.svg\n",
    "│   ├── nn-2.png\n",
    "│   ├── nn-2.svg\n",
    "│   ├── nn-3.png\n",
    "│   ├── nn-3.svg\n",
    "│   └── ohe.png\n",
    "└── saved_models\n",
    "```\n",
    "As you can see you will mostly be working with the `2025-Fall-DL-hw2.ipynb`, i.e., the jupyter notebook. The notebook accesses the dataset files: `dataset/datasetX.csv` containing few customer information and is labeled (i.e., the target column, `Exited` is present). Here below is a brief summary of the features you will find in the datasets:\n",
    "\n",
    "* `CustomerId`: a unique identifier for each customer within the dataset. These values are not ordered sequentially within the dataset, and are only used to identify a specific customer. It typically does not have any influence to whether a customer leaves the business.\n",
    "* `Surname`: A string used to identify the customer in the dataset. Surname may be distinct amidst all or most customers. Because of this, it most likely won't affect the target variable. \n",
    "* `CreditScore`: a numeric representation of the customer's individual fiscal credit score. Typically used to indicate eligibility for loans. Current credit scores use a range from 300 to 850, but the FICO auto score range uses 250-900. This feature likely determines retention rate of customers. \n",
    "* `Geography`: this feature contains a categorical string representing the name of a country the customer is from originally. \n",
    "* `Gender`: this feature contains a categorical string representing the gender of the customer (\"Male\"/\"Female\"). \n",
    "* `Age`: a numerical integer representation of a customer's age. Intuition suggests that older customers are likely to have higher retention than younger customers.\n",
    "* `Tenure`: a numerical integer representation. It is assumed that this feature represents the number of total years the customer has been retained. It is likely that customers which have been retained longer will continue to be retained.\n",
    "* `Balance`: a numerical floating point number (to two decimal places of precision) indicating the customer's current bank balance (assumed total across all accounts). Customers with a greater balance may be less likely to exit the account due to difficulty of transfer. \n",
    "* `NumOfProducts`: numeric integer value. It is assumed that this value represents the number of accounts (products) that this customer has open. Further evaluation of this feature would be needed to determine the usefulness of this feature, but at face-value, intuition dictates that a customer with more products is less likely to exit. \n",
    "* `HasCrCard`: boolean flag (0 or 1) representing whether the customer has a credit card or not. \n",
    "* `IsActiveMember`: boolean flag (0 or 1) representing whether the customer is an active member of the bank. It is assumed this indicates whether the customer has transactions on the regular banking statement. Intuition dictates that inactive members are more likely to exit. \n",
    "* `EstimatedSalary`: numerical floating point representation of the customer's predicted salary (to two decomal places) intuition dictates that customers with different incomes may behave differently with respect to retention rate. \n",
    "* `Exited`: boolean flag (0 or 1) representing whether the customer has exited their account. This is the target variable for the dataset. It should not be dropped, but should not be included as the training input (X), and should instead be separated as the target label (y). \n",
    "\n",
    "You will also see an empty directory `saved_models/`, that is for you to save all the models you'd train in this assignment.\n",
    "\n",
    "`figures/` directory contains few image files used to properly document this assignment. Please do not delete and when possible please move them with this jupyter notebook for proper display of its contents.\n",
    "\n",
    "> In this Jupyter notebook please write your solutions / codes in the cells marked with `#Your solution goes here...`. You may add additional code cells after that cell if you desire. But, please do not remove any cell originally given in the notebook.\n",
    "\n",
    "> After you solve the assignment in the jupyter notebook, be sure to execute and save it so that execution/results/printouts are also saved with it.\n",
    "> Finally, submit the saved jupyter notebook (`2025-Fall-DL-hw2.ipynb`) in Canvas to receive grade. Optionally, you can also submit a python version of the notebook if desired. For this assignment, Canvas only will accept either jupyter notebook in `*.ipynb` or python script (`*.py`) extensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 : (10 points)\n",
    "* Define a function named `summarize_dataset` that takes only one argument: `csv_file`, where `csv_file` is the name of the given `csv` file with this assignment, i.e., `datasetX.csv`. \n",
    "  * The function is expected to summarize the given dataset in the following way:\n",
    "```\n",
    "total number of rows = a\n",
    "total number of columns = b\n",
    "number of columns having non-numeric values = c\n",
    "columns with missing values = [ (d1, e1)  (d2, e2), ... ]\n",
    "gender based summary of exited column = [ (f1, g1)  (f2, g2), ... ]\n",
    "age based summary of exited column = [ ('below or equal to 40', h1)  ('above 40', h2) ]\n",
    "credit score summary =  i +/- j \n",
    "```\n",
    "  \n",
    "where,\n",
    "\n",
    "* `a` is total number of rows in the dataset.\n",
    "* `b` is total number of columns in the dataset.\n",
    "* `c` is number of columns having non-numeric values.\n",
    "* $(d_i, e_i)$ (i.e., a pair/tuple entry) represents column name ($d_i$) and number of missing values present in that column ($e_i$). If number of missing values in a column is zero (0), you do not need to list it. Please sort the tuple entries in descending order of $e_i$ values.\n",
    "* $g_i$ represents the percentage of gender $f_i$ who exited. Please sort the tuple entries entries in descending order of $g_i$ values. Also, print the percentages in 2 decimal places after the decimal point, and print use `%` symbol after the percentage value.\n",
    "* $h_1$ and $h_2$ represents the percentage of $\\leq 40$ year olds who exited, and the percentage $>40$ year olds who exited.  Also, print the percentages in 2 decimal places after the decimal point, and print use `%` symbol after the percentage value.\n",
    "* `j` and `k` are average and standard deviation of credit scores among the data samples respectively. Please print the way it is shown above. Also, print the both values in 2 decimal places after the decimal point.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of rows = 9000\n",
      "total number of columns = 13\n",
      "number of columns having non-numeric values = 3\n",
      "columns with missing values = [('Age', np.int64(397)), ('CreditScore', np.int64(26))]\n",
      "gender based summary of exited column = [('Female', '24.77%'), ('Male', '16.63%')]\n",
      "age based summary of exited column = [('below or equal to 40', '10.94%'), ('above 40', '37.63%')]\n",
      "credit score summary = 650.25 +/- 96.75\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def summarize_dataset(csv_file):\n",
    "    \"\"\"\n",
    "    Summarize the given dataset with various statistics\n",
    "    \"\"\"\n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # a) Total number of rows\n",
    "    total_rows = df.shape[0]\n",
    "    \n",
    "    # b) Total number of columns  \n",
    "    total_cols = df.shape[1]\n",
    "    \n",
    "    # c) Number of columns having non-numeric values\n",
    "    non_numeric_cols = len(df.select_dtypes(exclude=[np.number]).columns)\n",
    "    \n",
    "    # d) Columns with missing values\n",
    "    missing_values = []\n",
    "    for col in df.columns:\n",
    "        missing_count = df[col].isnull().sum()\n",
    "        if missing_count > 0:\n",
    "            missing_values.append((col, missing_count))\n",
    "    # Sort by number of missing values in descending order\n",
    "    missing_values.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # e) Gender based summary of exited column\n",
    "    gender_exit_summary = []\n",
    "    for gender in df['Gender'].unique():\n",
    "        if pd.notna(gender):  # Skip NaN values\n",
    "            gender_data = df[df['Gender'] == gender]\n",
    "            exit_percentage = (gender_data['Exited'].sum() / len(gender_data)) * 100\n",
    "            gender_exit_summary.append((gender, f\"{exit_percentage:.2f}%\"))\n",
    "    # Sort by percentage in descending order\n",
    "    gender_exit_summary.sort(key=lambda x: float(x[1].replace('%', '')), reverse=True)\n",
    "    \n",
    "    # f) Age based summary of exited column\n",
    "    age_exit_summary = []\n",
    "    # Below or equal to 40\n",
    "    age_below_40 = df[df['Age'] <= 40]\n",
    "    if len(age_below_40) > 0:\n",
    "        exit_pct_below_40 = (age_below_40['Exited'].sum() / len(age_below_40)) * 100\n",
    "        age_exit_summary.append(('below or equal to 40', f\"{exit_pct_below_40:.2f}%\"))\n",
    "    \n",
    "    # Above 40\n",
    "    age_above_40 = df[df['Age'] > 40]\n",
    "    if len(age_above_40) > 0:\n",
    "        exit_pct_above_40 = (age_above_40['Exited'].sum() / len(age_above_40)) * 100\n",
    "        age_exit_summary.append(('above 40', f\"{exit_pct_above_40:.2f}%\"))\n",
    "    \n",
    "    # g) Credit score summary (mean +/- std)\n",
    "    credit_mean = df['CreditScore'].mean()\n",
    "    credit_std = df['CreditScore'].std()\n",
    "    \n",
    "    # Print the summary\n",
    "    print(f\"total number of rows = {total_rows}\")\n",
    "    print(f\"total number of columns = {total_cols}\")\n",
    "    print(f\"number of columns having non-numeric values = {non_numeric_cols}\")\n",
    "    print(f\"columns with missing values = {missing_values}\")\n",
    "    print(f\"gender based summary of exited column = {gender_exit_summary}\")\n",
    "    print(f\"age based summary of exited column = {age_exit_summary}\")\n",
    "    print(f\"credit score summary = {credit_mean:.2f} +/- {credit_std:.2f}\")\n",
    "\n",
    "# Test the function\n",
    "summarize_dataset('dataset/datasetX.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "* Preprocessing the given dataset for the model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.1 (10 points)\n",
    "\n",
    "* First preprocessing that we are going to do on the dataset is dropping two features (i.e., columns) that, I think, are irrelevant and would not make any meaningful relationship with the `Exited` feature. The features are: `CustomerId` and `Surname`.\n",
    "* Make sure to create a variable called `dataset_dropped` that will store the revised dataset.\n",
    "* Please print the name of the columns of the revised dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-247a930d79bde8e3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the revised dataset:\n",
      "['CreditScore', 'Geography', 'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary', 'Exited']\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "dataset = pd.read_csv('dataset/datasetX.csv')\n",
    "\n",
    "# Drop CustomerId and Surname columns \n",
    "dataset_dropped = dataset.drop(['CustomerId', 'Surname'], axis=1)\n",
    "\n",
    "print(\"Columns in the revised dataset:\")\n",
    "print(list(dataset_dropped.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.2 (10 points)\n",
    "* Second Preprocessing that we are going to do is *Shuffle Rows* of the dataset obtained from `Task 2.1`.\n",
    "* \"It is extremely important to shuffle the training data, so that you do not obtain entire minibatches of highly correlated examples. As long as the data has been shuffled, everything should work OK. Different random orderings will perform slightly differently from each other but this will be a small factor that does not matter much.\" -- [Ian Goodfellow](https://qr.ae/pGBgw8)\n",
    "* Use a random seed value `4321` in case you will call any stochastic method.\n",
    "* Make sure to create a variable called `dataset_shuffled` that will store the revised dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "shuff_dataset_final",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shuffled successfully!\n",
      "Shape of shuffled dataset: (9000, 11)\n",
      "First 5 rows of shuffled dataset:\n",
      "   CreditScore Geography  Gender   Age  Tenure    Balance  NumOfProducts  \\\n",
      "0        538.0     Spain  Female  30.0       8       0.00              2   \n",
      "1        734.0    France    Male  37.0       3   80387.81              1   \n",
      "2        494.0    France  Female  35.0       9  112727.06              2   \n",
      "3        633.0    France    Male  38.0       2   91902.56              2   \n",
      "4        565.0   Germany    Male  31.0       2   89558.39              2   \n",
      "\n",
      "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
      "0          1               1         41192.95       0  \n",
      "1          0               1         77272.62       0  \n",
      "2          1               0        183752.91       0  \n",
      "3          1               1        107673.35       0  \n",
      "4          1               1          4441.54       0  \n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "np.random.seed(4321)\n",
    "\n",
    "# Shuffle the dataset\n",
    "dataset_shuffled = dataset_dropped.sample(frac=1, random_state=4321).reset_index(drop=True)\n",
    "\n",
    "print(\"Dataset shuffled successfully!\")\n",
    "print(f\"Shape: {dataset_shuffled.shape}\")\n",
    "print(\"First 5 rows:\")\n",
    "print(dataset_shuffled.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.3: (10 points)\n",
    "\n",
    "* Third Preprocessing that we will do is X-y Partitioning of the dataset obtained from `Task 2.2`.\n",
    "* In its current state, the dataset contains both independent (input, `X`) and the target (output, `y`) features within the same dataframe. For ease of of the training process, we need to partition the training features from the target feature into two separate dataframes. \n",
    "* Make sure, the following cell contains at least two variables: `X` and `y`:\n",
    "  * `X` contains part of the dataset with only independent features, and \n",
    "  * `y` having only the dependent/target feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix X shape: (9000, 10)\n",
      "Target vector y shape: (9000,)\n",
      "\n",
      "Feature columns:\n",
      "['CreditScore', 'Geography', 'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary']\n",
      "\n",
      "Target distribution:\n",
      "Exited\n",
      "0    7169\n",
      "1    1831\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Split features and target\n",
    "X = dataset_shuffled.drop('Exited', axis=1)  \n",
    "y = dataset_shuffled['Exited']  \n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "print(\"\\nFeatures:\")\n",
    "print(list(X.columns))\n",
    "print(\"\\nTarget distribution:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.4 (10 points)\n",
    "* Fourth Preprocessing that we will do is Train-Test Split of X, y obtained from `Task 2.3`.\n",
    "* Now that we have X and y tables with appropriate feature pruning performed, we must split the data into a training partition (`X_train, y_train`) and a testing partition (`X_test, y_test`). \n",
    "* The training partitions (`X_train, y_train`) will be used to train your model, while the test partition (`X_test, y_test`) will be set aside during the training steps, and will only be used to evaluate the trained model. \n",
    "* Training and test splits should be mutually exclusive to the datasets... i.e., a sample can not be both in training and test sets.\n",
    "* Please perform a 80-20 split, meaning 80% of the (X,y) dataset will be in (X_train, y_train) split, while, remaining 20% will be in (X_test,y_test) split. \n",
    "* Please use random seed `4321` prior to calling any stochastic methods.\n",
    "* Make sure the following cell contains at least 4 variables: `X_train`, `y_train`, `X_test`, `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "train_test_split",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "X_train shape: (7200, 10)\n",
      "y_train shape: (7200,)\n",
      "y_train distribution:\n",
      "Exited\n",
      "0    5735\n",
      "1    1465\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test set:\n",
      "X_test shape: (1800, 10)\n",
      "y_test shape: (1800,)\n",
      "y_test distribution:\n",
      "Exited\n",
      "0    1434\n",
      "1     366\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Train set percentage: 80.0%\n",
      "Test set percentage: 20.0%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 80-20 train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=4321,\n",
    "    stratify=y  \n",
    ")\n",
    "\n",
    "print(\"Training set:\")\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"y_train: {y_train.shape}\")\n",
    "print(f\"y_train distribution:\\n{y_train.value_counts()}\")\n",
    "\n",
    "print(\"\\nTest set:\")\n",
    "print(f\"X_test: {X_test.shape}\")\n",
    "print(f\"y_test: {y_test.shape}\")\n",
    "print(f\"y_test distribution:\\n{y_test.value_counts()}\")\n",
    "\n",
    "print(f\"\\nTrain: {len(X_train)/len(X)*100:.1f}%\")\n",
    "print(f\"Test: {len(X_test)/len(X)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.5 (10 points)\n",
    "\n",
    "* Fifth preprocessing that we will do is the *Conversion of Categorical features to Numerical*\n",
    "* Please adopt the `One Hot Encoding` method instead of `Label Encoding` while converting the categorical features. \n",
    "* Make sure the following cell contains a variable named `X_train_ohe` that would contain one hot encoded `X_train` data; on the two categorical columns: 'Geography','Gender'. Please save the encoder for later use; e.g., encode `X_test` dataset, or any future test sample given to you. Under any circumstance, you must not encode `X_test` independently like you would do for `X_train`.\n",
    "* Now, encode the `X_test` data using the one hot encoder you saved while you encoded the `X_train`, and name the variable `X_test_ohe`.\n",
    "\n",
    "\n",
    "* **Both encoding techniques are outlined below**:\n",
    "> A little background first: Categorical features are features that contain values that are not numeric. It would be absurd to work with non-numeric features if you ask neurons in your ANN to compute the weighted sum of inputs, and then pass through activation function, right? These maths are undefined. An obvious solution you may be intrigued to do is dropping the features! Aha! Wrong!! Every piece of data is precious... may present with valuable insights of the data samples to find the patterns to map inputs with output/targets. So, we should include them. But, how?\n",
    "\n",
    "The answer is via \"Encoding\". \n",
    "\n",
    "Several types of encodings are used in practice. Here below are just 2 popular ones:\n",
    "1. **Label Encoding**, where labels are encoded as subsequent numbers. Say, for a categorical feature named \"Category\" with three categorical values: {“Cat”, “Dog” or “Zebra”} can be encoded to \"0\", \"1\", \"2\" respectively as in figure below. The issue with this type of encoding may unintentionally impose a type of ordering of the categories, that may add bias to the training.\n",
    "\n",
    "\n",
    "![label-encoding](figures/le.png)\n",
    "\n",
    "2. **One Hot Encoding**, ignores the ordering of the categories all together. With one-hot, we convert each categorical value into a new categorical column and assign a binary value of 1 or 0 to those columns. Each integer value is represented as a binary vector. All the values are zero, and the index is marked with a 1. Also, don't forget to remove the original categorical features. Here below just an example, how to convert the categorical feature called \"Category\" having the {“Cat”, “Dog” or “Zebra”} values into three new binary features: \"Cat\", \"Dog\", \"Zebra\".\n",
    "\n",
    "![label-encoding](figures/ohe.png)\n",
    "\n",
    "**A note on the Dummy Variable Trap**\n",
    "The Dummy Variable Trap occurs when two or more dummy variables created by one-hot encoding are highly correlated (i.e., becomes multi-collinear). This means that one variable can be predicted from the others, making it difficult to interpret predicted coefficient variables in regression models. In other words, the individual effect of the dummy variables on the prediction model can not be interpreted well because of multicollinearity.\n",
    "\n",
    "Using the one-hot encoding method, a new dummy variable is created for each categorical variable to represent the presence (1) or absence (0) of the categorical variable. For example, if tree species is a categorical variable made up of the values pine, or oak, then tree species can be represented as a dummy variable by converting each variable to a one-hot vector. This means that a separate column is obtained for each category, where the first column represents if the tree is pine and the second column represents if the tree is oak. Each column will contain a 0 or 1 if the tree in question is of the column's species. These two columns are multi-collinear since if a tree is pine, then we know it's not oak and vice versa. The machine learning models trained on dataset having this multi-collinearity suffers. A remedy is to drop first (or any one) of the dummy (i.e., one-hot) features created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "one-hot-encoding-function",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot encoding completed!\n",
      "Original X_train shape: (7200, 10)\n",
      "Encoded X_train_ohe shape: (7200, 11)\n",
      "Original X_test shape: (1800, 10)\n",
      "Encoded X_test_ohe shape: (1800, 11)\n",
      "\n",
      "Encoded feature names:\n",
      "['Geography_Germany', 'Geography_Spain', 'Gender_Male']\n",
      "\n",
      "Final columns in X_train_ohe:\n",
      "['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary', 'Geography_Germany', 'Geography_Spain', 'Gender_Male']\n",
      "\n",
      "First 5 rows of X_train_ohe:\n",
      "   CreditScore   Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
      "0        619.0  45.0       0       0.00              2          0   \n",
      "1        747.0  40.0       3       0.00              1          0   \n",
      "2        608.0  66.0       8  123935.35              1          1   \n",
      "3        664.0  57.0       1       0.00              2          1   \n",
      "4        651.0  63.0       8  129968.67              1          1   \n",
      "\n",
      "   IsActiveMember  EstimatedSalary  Geography_Germany  Geography_Spain  \\\n",
      "0               0        113645.40                0.0              1.0   \n",
      "1               0         57817.84                0.0              0.0   \n",
      "2               1         65758.19                0.0              1.0   \n",
      "3               1         56562.57                0.0              0.0   \n",
      "4               1         11830.53                0.0              1.0   \n",
      "\n",
      "   Gender_Male  \n",
      "0          0.0  \n",
      "1          0.0  \n",
      "2          1.0  \n",
      "3          1.0  \n",
      "4          0.0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# One-hot encode categorical columns\n",
    "categorical_columns = ['Geography', 'Gender']\n",
    "\n",
    "# Fit encoder on training data only\n",
    "ohe = OneHotEncoder(drop='first', sparse_output=False)  \n",
    "ohe.fit(X_train[categorical_columns])\n",
    "\n",
    "# Transform both train and test\n",
    "X_train_categorical_encoded = ohe.transform(X_train[categorical_columns])\n",
    "X_test_categorical_encoded = ohe.transform(X_test[categorical_columns])\n",
    "\n",
    "# Get new column names\n",
    "encoded_feature_names = ohe.get_feature_names_out(categorical_columns)\n",
    "\n",
    "# Create DataFrames\n",
    "X_train_categorical_df = pd.DataFrame(X_train_categorical_encoded, \n",
    "                                    columns=encoded_feature_names, \n",
    "                                    index=X_train.index)\n",
    "\n",
    "X_test_categorical_df = pd.DataFrame(X_test_categorical_encoded, \n",
    "                                   columns=encoded_feature_names, \n",
    "                                   index=X_test.index)\n",
    "\n",
    "# Get numerical columns\n",
    "numerical_columns = [col for col in X_train.columns if col not in categorical_columns]\n",
    "\n",
    "# Combine numerical and encoded categorical\n",
    "X_train_ohe = pd.concat([X_train[numerical_columns].reset_index(drop=True), \n",
    "                         X_train_categorical_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "X_test_ohe = pd.concat([X_test[numerical_columns].reset_index(drop=True), \n",
    "                        X_test_categorical_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "print(\"One-hot encoding done!\")\n",
    "print(f\"Original X_train: {X_train.shape}\")\n",
    "print(f\"Encoded X_train_ohe: {X_train_ohe.shape}\")\n",
    "print(f\"Original X_test: {X_test.shape}\")\n",
    "print(f\"Encoded X_test_ohe: {X_test_ohe.shape}\")\n",
    "\n",
    "print(\"\\nNew encoded features:\")\n",
    "print(list(encoded_feature_names))\n",
    "\n",
    "print(\"\\nFinal columns:\")\n",
    "print(list(X_train_ohe.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.6: (10 points)\n",
    "\n",
    "* Sixth Preprocessing that we are going to do is *Normalization of X_train_ohe, and X_test_ohe*\n",
    "\n",
    "* Now that we have all numerical training and test datasets: `X_train_ohe` and `X_test_ohe` respectively, we can normalize each features in both of the datasets. **Normalization** is just one of the way to scale each feature. In class you'll learn a ton of other ways to scale. For this task, let's resort to **Normalization**.\n",
    "\n",
    "> \"The rule of thumb for scaling datasets, is we scale training dataset first, then using the statistics that we learn during the scaling process, we scale the test dataset. We do not learn any new statistics while we scale the test dataset.\"\n",
    "\n",
    "* Also, scaling is commonly performed column-wise, and never sample/row wise.\n",
    "\n",
    "* Make sure the following cell contains the two scaled variables: `X_train_scaled` and `X_test_scaled` based on the requirements mentioned above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "normalizer-learning-training",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalization completed!\n",
      "X_train_scaled shape: (7200, 11)\n",
      "X_test_scaled shape: (1800, 11)\n",
      "\n",
      "Training data statistics after scaling:\n",
      "Min values: 0.000000\n",
      "Max values: 1.000000\n",
      "Mean values: 0.419961\n",
      "\n",
      "Test data statistics after scaling:\n",
      "Min values: 0.000000\n",
      "Max values: 1.000000\n",
      "Mean values: 0.424509\n",
      "\n",
      "First 5 rows of X_train_scaled:\n",
      "   CreditScore       Age  Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
      "0        0.538  0.364865     0.0  0.000000       0.333333        0.0   \n",
      "1        0.794  0.297297     0.3  0.000000       0.000000        0.0   \n",
      "2        0.516  0.648649     0.8  0.493967       0.000000        1.0   \n",
      "3        0.628  0.527027     0.1  0.000000       0.333333        1.0   \n",
      "4        0.602  0.608108     0.8  0.518014       0.000000        1.0   \n",
      "\n",
      "   IsActiveMember  EstimatedSalary  Geography_Germany  Geography_Spain  \\\n",
      "0             0.0         0.568054                0.0              1.0   \n",
      "1             0.0         0.288780                0.0              0.0   \n",
      "2             1.0         0.328501                0.0              1.0   \n",
      "3             1.0         0.282500                0.0              0.0   \n",
      "4             1.0         0.058731                0.0              1.0   \n",
      "\n",
      "   Gender_Male  \n",
      "0          0.0  \n",
      "1          0.0  \n",
      "2          1.0  \n",
      "3          1.0  \n",
      "4          0.0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Scale the data\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit on training data and transform\n",
    "X_train_scaled = scaler.fit_transform(X_train_ohe)\n",
    "X_test_scaled = scaler.transform(X_test_ohe)\n",
    "\n",
    "# Convert back to DataFrames\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train_ohe.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test_ohe.columns)\n",
    "\n",
    "print(\"Scaling done!\")\n",
    "print(f\"X_train_scaled: {X_train_scaled.shape}\")\n",
    "print(f\"X_test_scaled: {X_test_scaled.shape}\")\n",
    "\n",
    "print(f\"\\nTrain data - Min: {X_train_scaled.min().min():.3f}, Max: {X_train_scaled.max().max():.3f}\")\n",
    "print(f\"Test data - Min: {X_test_scaled.min().min():.3f}, Max: {X_test_scaled.max().max():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: (10 points)\n",
    "* *Designing your first Artificial Neural Network (ANN) based classifier* using **PyTorch**.:\n",
    "\n",
    "\n",
    "### Step 0: Dataset and DataLoaders\n",
    "* Make sure you implement the `Dataset` and `DataLoader` classes ready to read from the external csv file located at `dataset/datasetX.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for NaN values:\n",
      "X_train_scaled NaN count: 341\n",
      "X_test_scaled NaN count: 82\n",
      "y_train NaN count: 0\n",
      "y_test NaN count: 0\n",
      "\n",
      "After cleaning:\n",
      "X_train_scaled_clean NaN count: 0\n",
      "X_test_scaled_clean NaN count: 0\n",
      "\n",
      "Training dataset size: 7200\n",
      "Test dataset size: 1800\n",
      "Number of training batches: 225\n",
      "Number of test batches: 57\n",
      "Feature dimensions: 11\n",
      "\n",
      "Sample input shape: torch.Size([11])\n",
      "Sample target shape: torch.Size([])\n",
      "Sample input: tensor([0.5380, 0.3649, 0.0000, 0.0000, 0.3333])\n",
      "Sample target: 0.0\n",
      "Sample input min/max: 0.0000/1.0000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# Check for NaN values\n",
    "print(\"Checking for NaN values:\")\n",
    "print(f\"X_train_scaled NaN: {X_train_scaled.isnull().sum().sum()}\")\n",
    "print(f\"X_test_scaled NaN: {X_test_scaled.isnull().sum().sum()}\")\n",
    "\n",
    "# Fill NaN with 0\n",
    "X_train_scaled_clean = X_train_scaled.fillna(0)\n",
    "X_test_scaled_clean = X_test_scaled.fillna(0)\n",
    "\n",
    "print(f\"After cleaning: {X_train_scaled_clean.isnull().sum().sum()} NaNs\")\n",
    "\n",
    "# Dataset class\n",
    "class CustomerChurnDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.FloatTensor(X.values if hasattr(X, 'values') else X)\n",
    "        self.y = torch.FloatTensor(y.values if hasattr(y, 'values') else y)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = CustomerChurnDataset(X_train_scaled_clean, y_train)\n",
    "test_dataset = CustomerChurnDataset(X_test_scaled_clean, y_test)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"\\nDataset ready:\")\n",
    "print(f\"Training: {len(train_dataset)} samples\")\n",
    "print(f\"Test: {len(test_dataset)} samples\")\n",
    "print(f\"Features: {X_train_scaled_clean.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: The ANN architecture\n",
    "* Let's design the first artificial network architecture for the classifier we would like to build. Here below is one. How did I get this architecture? Maybe in my dream! Haha. Someday you will get one too. Until that, let's follow the architecture below:\n",
    "  ![Task 3 ANN architecture](figures/nn-1.png)\n",
    "  * **Input layer** will have 11 units as the dimension of training set: `X_train_scaled` (i.e, number of columns = 11).\n",
    "  * **First hidden layer** will have 5 neurons, each with \"Rectified Linear Unit (`ReLU``)\" as activation function.\n",
    "  * **Second hidden layer** will have 4 neurons, each with \"`ReLU`\" as activation function.\n",
    "  * **Output layer** will have just 1 neuron, with `sigmoid`` activation function. \n",
    "    * The reason behind a single neuron with `sigmoid` activation at the output layer is that, output of this neuron will tell the probability score of the target outcome: \"Exited\" True or False. If the output neuron produces value above 0.5, we will say the neural network predicted \"True\", otherwise, False. This is the beauty of using sigmoid function at the output layer as we can interpret the output value of the neuron as probability score.\n",
    "* The architecture will come to life when you initiate the training process with training data.\n",
    "  * The training process needs a **gradient descend based optimizer**, and a convex looking **loss function**.  \n",
    "  * For this task, let's choose the `adam` optimizer, and the `binary_crossentropy` as the loss function.\n",
    "  * You choose a batch size that would make the execution comfortable at your workstation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Architecture:\n",
      "ANN_11_5_4_1(\n",
      "  (hidden1): Linear(in_features=11, out_features=5, bias=True)\n",
      "  (hidden2): Linear(in_features=5, out_features=4, bias=True)\n",
      "  (output): Linear(in_features=4, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "\n",
      "Total parameters: 89\n",
      "hidden1.weight: torch.Size([5, 11])\n",
      "hidden1.bias: torch.Size([5])\n",
      "hidden2.weight: torch.Size([4, 5])\n",
      "hidden2.bias: torch.Size([4])\n",
      "output.weight: torch.Size([1, 4])\n",
      "output.bias: torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "# Neural network: 11-5-4-1\n",
    "class ANN_11_5_4_1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ANN_11_5_4_1, self).__init__()\n",
    "        self.hidden1 = nn.Linear(11, 5)\n",
    "        self.hidden2 = nn.Linear(5, 4)\n",
    "        self.output = nn.Linear(4, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.hidden1(x))\n",
    "        x = self.relu(self.hidden2(x))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x\n",
    "\n",
    "# Create model\n",
    "model_11_5_4_1 = ANN_11_5_4_1()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model_11_5_4_1.parameters(), lr=0.001)\n",
    "\n",
    "print(\"Model Architecture:\")\n",
    "print(model_11_5_4_1)\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model_11_5_4_1.parameters())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: The Training process\n",
    "* Let's start the training process with the training dataset, `X_train_scaled`.\n",
    "  * Gradient descend based optimization updates run in iterations. When number of iterations equal the total number of training samples, we call that `1 epoch` has passed. Let's continue the training for `25 epochs`. But, you are welcome to run longer than this. There are, however, simpler way to determine if you should early stop your training. \n",
    "    * (Optional) Can you extract information about optimization in each epoch? If so, draw a epoch-loss plot, where X-axis needs to show epoch numbers, and Y-axis will show the `binary_crossentropy` loss value in that particular epoch iteration.\n",
    "* Don't forget to save the model into a file in the `saved_models/` directory so that you can re-use it later for further prediction. Let's give it a name: `model-ann-11-5-4-1-pt` with an extension of your choosing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "==================================================\n",
      "Epoch [1/25], Loss: 0.6773, Accuracy: 0.5100\n",
      "Epoch [5/25], Loss: 0.4572, Accuracy: 0.8000\n",
      "Epoch [5/25], Loss: 0.4572, Accuracy: 0.8000\n",
      "Epoch [10/25], Loss: 0.4310, Accuracy: 0.8125\n",
      "Epoch [10/25], Loss: 0.4310, Accuracy: 0.8125\n",
      "Epoch [15/25], Loss: 0.4269, Accuracy: 0.8125\n",
      "Epoch [15/25], Loss: 0.4269, Accuracy: 0.8125\n",
      "Epoch [20/25], Loss: 0.4259, Accuracy: 0.8111\n",
      "Epoch [20/25], Loss: 0.4259, Accuracy: 0.8111\n",
      "Epoch [25/25], Loss: 0.4255, Accuracy: 0.8090\n",
      "==================================================\n",
      "Training completed!\n",
      "Epoch [25/25], Loss: 0.4255, Accuracy: 0.8090\n",
      "==================================================\n",
      "Training completed!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model saved as 'saved_models/model-ann-11-5-4-1-pt.pth'\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Training\n",
    "epochs = 25\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "\n",
    "print(\"Training...\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model_11_5_4_1.train()\n",
    "    epoch_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for data, targets in train_loader:\n",
    "        outputs = model_11_5_4_1(data)\n",
    "        loss = criterion(outputs.squeeze(), targets)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        predicted = (outputs.squeeze() > 0.5).float()\n",
    "        correct += (predicted == targets).sum().item()\n",
    "        total += targets.size(0)\n",
    "    \n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    accuracy = correct / total\n",
    "    \n",
    "    train_losses.append(avg_loss)\n",
    "    train_accuracies.append(accuracy)\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"Epoch {epoch+1}: Loss={avg_loss:.4f}, Acc={accuracy:.4f}\")\n",
    "\n",
    "print(\"Training done!\")\n",
    "\n",
    "# Plot results\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax1.plot(range(1, epochs+1), train_losses, 'b-')\n",
    "ax1.set_title('Training Loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "\n",
    "ax2.plot(range(1, epochs+1), train_accuracies, 'r-')\n",
    "ax2.set_title('Training Accuracy')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save model\n",
    "os.makedirs('saved_models', exist_ok=True)\n",
    "torch.save(model_11_5_4_1.state_dict(), 'saved_models/model-ann-11-5-4-1-pt.pth')\n",
    "print(\"Model saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: The Evaluation\n",
    "\n",
    "#### (part 3.1) Evaluating your model with the entire test dataset:\n",
    "\n",
    "* Load your trained model `model-ann-11-5-4-1-pt` from the file, and have it predict the entire test set you have at head: (`X_test_scaled`). Luckily, for each of the test sample in the set, you also have ground true `Exited` value in the `y_test`. \n",
    "* Please report/print your model's predictive performance on the test set in terms of `accuracy`, `precision`, `recall`, and `F1 scores`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n",
      "Evaluating on test dataset...\n",
      "============================================================\n",
      "MODEL PERFORMANCE ON TEST SET\n",
      "============================================================\n",
      "Accuracy:  0.8067 (80.67%)\n",
      "Precision: 0.5542 (55.42%)\n",
      "Recall:    0.2514 (25.14%)\n",
      "F1 Score:  0.3459 (34.59%)\n",
      "============================================================\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Not Exited       0.83      0.95      0.89      1434\n",
      "      Exited       0.55      0.25      0.35       366\n",
      "\n",
      "    accuracy                           0.81      1800\n",
      "   macro avg       0.69      0.60      0.62      1800\n",
      "weighted avg       0.78      0.81      0.78      1800\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1360   74]\n",
      " [ 274   92]]\n",
      "\n",
      "Confusion Matrix Interpretation:\n",
      "True Negatives (TN):  1360 - Correctly predicted as Not Exited\n",
      "False Positives (FP): 74 - Incorrectly predicted as Exited\n",
      "False Negatives (FN): 274 - Incorrectly predicted as Not Exited\n",
      "True Positives (TP):  92 - Correctly predicted as Exited\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "# Load and evaluate model\n",
    "model_loaded = ANN_11_5_4_1()\n",
    "model_loaded.load_state_dict(torch.load('saved_models/model-ann-11-5-4-1-pt.pth'))\n",
    "model_loaded.eval()\n",
    "\n",
    "# Test the model\n",
    "all_predictions = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, targets in test_loader:\n",
    "        outputs = model_loaded(data)\n",
    "        predictions = (outputs.squeeze() > 0.5).float()\n",
    "        \n",
    "        all_predictions.extend(predictions.cpu().numpy())\n",
    "        all_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "all_predictions = np.array(all_predictions)\n",
    "all_targets = np.array(all_targets)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(all_targets, all_predictions)\n",
    "precision = precision_score(all_targets, all_predictions)\n",
    "recall = recall_score(all_targets, all_predictions)\n",
    "f1 = f1_score(all_targets, all_predictions)\n",
    "\n",
    "print(\"TEST RESULTS\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Accuracy:  {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_targets, all_predictions, target_names=['Not Exited', 'Exited']))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(all_targets, all_predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (part 3.2) Evaluating your model with 1 test sample with known Exited value\n",
    "\n",
    "* Here is a single test sample for which we know the ground true `Exited` value:\n",
    "\n",
    "| CustomerId | Surname | CreditScore | Geography | Gender | Age | Tenure | Balance | NumOfProducts | HasCrCard | IsActiveMember |EstimatedSalary | Exited |\n",
    "| :---        |    :----:   |          ---: | :---        |    :----:   |          ---: | :---        |    :----:   |          ---: | :---        |    :----:   |          ---: |          ---: |\n",
    "| 55443322 | Reynolds |709|Germany|Male|30|9|115479.48|2|1|1|134732.99|0|\n",
    "\n",
    "* Load your trained model `model-ann-11-5-4-1-pt` from the file, and have it predict the test sample above. Please don't forget to preprocess this test samples so that it is compliant with the input and model requirements.\n",
    "* Please report whether it predicts a 0 or 1 for the `Exited` target, and also comment whether your model makes a mistake or predicts correctly.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Test Sample Evaluation\n",
      "==================================================\n",
      "Input sample:\n",
      "  CreditScore: 709\n",
      "  Geography: Germany\n",
      "  Gender: Male\n",
      "  Age: 30\n",
      "  Tenure: 9\n",
      "  Balance: 115479.48\n",
      "  NumOfProducts: 2\n",
      "  HasCrCard: 1\n",
      "  IsActiveMember: 1\n",
      "  EstimatedSalary: 134732.99\n",
      "\n",
      "Ground Truth Exited: 0\n",
      "\n",
      "Preprocessed sample shape: (1, 11)\n",
      "Preprocessed sample:\n",
      "   CreditScore       Age  Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
      "0        0.718  0.162162     0.9  0.460264       0.333333        1.0   \n",
      "\n",
      "   IsActiveMember  EstimatedSalary  Geography_Germany  Geography_Spain  \\\n",
      "0             1.0         0.673543                1.0              0.0   \n",
      "\n",
      "   Gender_Male  \n",
      "0          1.0  \n",
      "\n",
      "==================================================\n",
      "PREDICTION RESULTS\n",
      "==================================================\n",
      "Prediction probability: 0.0713\n",
      "Prediction class: 0\n",
      "Ground truth: 0\n",
      "Prediction correct: True\n",
      " The model predicted correctly!\n",
      "\n",
      "Interpretation: The model predicts that this customer will NOT EXIT the bank.\n"
     ]
    }
   ],
   "source": [
    "# Test sample with known result\n",
    "test_sample = {\n",
    "    'CreditScore': 709,\n",
    "    'Geography': 'Germany', \n",
    "    'Gender': 'Male',\n",
    "    'Age': 30,\n",
    "    'Tenure': 9,\n",
    "    'Balance': 115479.48,\n",
    "    'NumOfProducts': 2,\n",
    "    'HasCrCard': 1,\n",
    "    'IsActiveMember': 1,\n",
    "    'EstimatedSalary': 134732.99,\n",
    "    'Exited': 0  # Ground truth\n",
    "}\n",
    "\n",
    "print(\"Single Test Sample\")\n",
    "print(\"=\" * 30)\n",
    "for key, value in test_sample.items():\n",
    "    if key != 'Exited':\n",
    "        print(f\"{key}: {value}\")\n",
    "print(f\"Ground Truth: {test_sample['Exited']}\")\n",
    "\n",
    "# Preprocess the sample\n",
    "sample_df = pd.DataFrame([test_sample])\n",
    "sample_df = sample_df.drop(['Exited'], axis=1)\n",
    "\n",
    "# One-hot encode\n",
    "sample_categorical = sample_df[['Geography', 'Gender']]\n",
    "sample_categorical_encoded = ohe.transform(sample_categorical)\n",
    "sample_categorical_df = pd.DataFrame(sample_categorical_encoded, columns=encoded_feature_names)\n",
    "\n",
    "# Combine features\n",
    "sample_numerical = sample_df.drop(['Geography', 'Gender'], axis=1)\n",
    "sample_processed = pd.concat([sample_numerical.reset_index(drop=True), \n",
    "                             sample_categorical_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Scale\n",
    "sample_scaled = scaler.transform(sample_processed)\n",
    "sample_tensor = torch.FloatTensor(sample_scaled)\n",
    "\n",
    "# Predict\n",
    "model_loaded.eval()\n",
    "with torch.no_grad():\n",
    "    prediction_prob = model_loaded(sample_tensor).item()\n",
    "    prediction_class = 1 if prediction_prob > 0.5 else 0\n",
    "\n",
    "print(f\"\\nPrediction: {prediction_class} (prob: {prediction_prob:.4f})\")\n",
    "print(f\"Ground truth: {test_sample['Exited']}\")\n",
    "print(f\"Correct: {prediction_class == test_sample['Exited']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (part 3.3) Evaluating your model with 1 test sample without known Exited value\n",
    "\n",
    "* Here is a single test sample for which we **do not know** the ground true `Exited` value:\n",
    "\n",
    "| CustomerId | Surname | CreditScore | Geography | Gender | Age | Tenure | Balance | NumOfProducts | HasCrCard | IsActiveMember |EstimatedSalary | \n",
    "| :---        |    :----:   |          ---: | :---        |    :----:   |          ---: | :---        |    :----:   |          ---: | :---        |    :----:   |          ---: |\n",
    "| 55443323 | Nguyen |603|France|Female|76|20|123456.78|5|1|1|55000.00|\n",
    "\n",
    "\n",
    "* Load your trained model `model-ann-11-5-4-1-pt` from the file, and have it predict the test sample above. Please don't forget to preprocess this test samples so that it is compliant with the input and model requirements.\n",
    "* Please report whether it predicts a 0 or 1 for the `Exited` target. Can you comment on this data sample whether your model captured the pattern in the population?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "ANN-1_layers",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Test Sample Evaluation (Unknown Ground Truth)\n",
      "============================================================\n",
      "Input sample:\n",
      "  CreditScore: 603\n",
      "  Geography: France\n",
      "  Gender: Female\n",
      "  Age: 76\n",
      "  Tenure: 20\n",
      "  Balance: 123456.78\n",
      "  NumOfProducts: 5\n",
      "  HasCrCard: 1\n",
      "  IsActiveMember: 1\n",
      "  EstimatedSalary: 55000.0\n",
      "\n",
      "Preprocessed sample shape: (1, 11)\n",
      "Preprocessed sample:\n",
      "   CreditScore       Age  Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
      "0        0.506  0.783784     2.0  0.492059       1.333333        1.0   \n",
      "\n",
      "   IsActiveMember  EstimatedSalary  Geography_Germany  Geography_Spain  \\\n",
      "0             1.0         0.274684                0.0              0.0   \n",
      "\n",
      "   Gender_Male  \n",
      "0          0.0  \n",
      "\n",
      "============================================================\n",
      "PREDICTION RESULTS\n",
      "============================================================\n",
      "Prediction probability: 0.5109\n",
      "Prediction class: 1\n",
      "\n",
      "Interpretation: The model predicts that this customer will EXIT the bank.\n",
      "\n",
      "============================================================\n",
      "CUSTOMER PROFILE ANALYSIS\n",
      "============================================================\n",
      "Key characteristics of this customer:\n",
      "• Age: 76 years (elderly customer)\n",
      "• Credit Score: 603 (below average)\n",
      "• Geography: France (French customer)\n",
      "• Gender: Female\n",
      "• Tenure: 20 years (long-term customer)\n",
      "• Balance: $123,456.78 (substantial balance)\n",
      "• Number of Products: 5 (multiple products)\n",
      "• Has Credit Card: Yes\n",
      "• Active Member: Yes\n",
      "• Estimated Salary: $55,000.00\n",
      "\n",
      "============================================================\n",
      "PATTERN ANALYSIS\n",
      "============================================================\n",
      "The model predicts this customer will EXIT. This could be because:\n",
      "• Advanced age (76) might indicate lifestyle changes\n",
      "• Lower credit score (603) might indicate financial stress\n",
      "• Female customers showed higher exit rates in our analysis\n",
      "\n",
      "Confidence: Low\n",
      "The model seems to have captured meaningful patterns as the prediction\n",
      "considers multiple factors including demographics, financial status, and relationship depth.\n"
     ]
    }
   ],
   "source": [
    "# Test sample without known result\n",
    "unknown_sample = {\n",
    "    'CreditScore': 603,\n",
    "    'Geography': 'France', \n",
    "    'Gender': 'Female',\n",
    "    'Age': 76,\n",
    "    'Tenure': 20,\n",
    "    'Balance': 123456.78,\n",
    "    'NumOfProducts': 5,\n",
    "    'HasCrCard': 1,\n",
    "    'IsActiveMember': 1,\n",
    "    'EstimatedSalary': 55000.00\n",
    "}\n",
    "\n",
    "print(\"Unknown Sample Test\")\n",
    "print(\"=\" * 30)\n",
    "for key, value in unknown_sample.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Preprocess the sample\n",
    "unknown_df = pd.DataFrame([unknown_sample])\n",
    "\n",
    "# One-hot encode\n",
    "unknown_categorical = unknown_df[['Geography', 'Gender']]\n",
    "unknown_categorical_encoded = ohe.transform(unknown_categorical)\n",
    "unknown_categorical_df = pd.DataFrame(unknown_categorical_encoded, columns=encoded_feature_names)\n",
    "\n",
    "# Combine features\n",
    "unknown_numerical = unknown_df.drop(['Geography', 'Gender'], axis=1)\n",
    "unknown_processed = pd.concat([unknown_numerical.reset_index(drop=True), \n",
    "                              unknown_categorical_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Scale and predict\n",
    "unknown_scaled = scaler.transform(unknown_processed)\n",
    "unknown_tensor = torch.FloatTensor(unknown_scaled)\n",
    "\n",
    "model_loaded.eval()\n",
    "with torch.no_grad():\n",
    "    prediction_prob = model_loaded(unknown_tensor).item()\n",
    "    prediction_class = 1 if prediction_prob > 0.5 else 0\n",
    "\n",
    "print(f\"\\nPrediction: {prediction_class} (prob: {prediction_prob:.4f})\")\n",
    "result = \"EXIT\" if prediction_class == 1 else \"NOT EXIT\"\n",
    "print(f\"Customer will: {result}\")\n",
    "\n",
    "# Quick analysis\n",
    "print(f\"\\nAnalysis: 76-year-old female, long tenure (20 years), many products (5)\")\n",
    "if prediction_class == 1:\n",
    "    print(\"Model predicts exit - possibly due to age and lower credit score\")\n",
    "else:\n",
    "    print(\"Model predicts stay - tenure and multiple products suggest loyalty\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: (10 points)\n",
    "\n",
    "* Repeat all the steps in Task 3 with the following new architecture of the neural network:\n",
    "\n",
    "![Task 4 ANN architecture](figures/nn-2.png)\n",
    "\n",
    "* Input layer will still have 11 units as the dimension of training set (i.e, number of columns = 11).\n",
    "* Hidden-layer-1: 8 neurons, with relu activation\n",
    "* Hidden-layer-2: 8 neurons, with relu activation,\n",
    "* Hidden-layer-3: 8 neurons, with relu activation,\n",
    "* Output-layer: 1 neuron with sigmoid.\n",
    "\n",
    "* You may re-use the Dataset/Dataloader classes you defined in Task 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 4 - Model Architecture (11-8-8-8-1):\n",
      "ANN_11_8_8_8_1(\n",
      "  (hidden1): Linear(in_features=11, out_features=8, bias=True)\n",
      "  (hidden2): Linear(in_features=8, out_features=8, bias=True)\n",
      "  (hidden3): Linear(in_features=8, out_features=8, bias=True)\n",
      "  (output): Linear(in_features=8, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "\n",
      "Total parameters: 249\n",
      "\n",
      "Starting training for Task 4...\n",
      "==================================================\n",
      "Epoch [1/25], Loss: 0.5642, Accuracy: 0.7965\n",
      "Epoch [1/25], Loss: 0.5642, Accuracy: 0.7965\n",
      "Epoch [5/25], Loss: 0.4394, Accuracy: 0.8007\n",
      "Epoch [5/25], Loss: 0.4394, Accuracy: 0.8007\n",
      "Epoch [10/25], Loss: 0.4241, Accuracy: 0.8147\n",
      "Epoch [10/25], Loss: 0.4241, Accuracy: 0.8147\n",
      "Epoch [15/25], Loss: 0.4209, Accuracy: 0.8187\n",
      "Epoch [15/25], Loss: 0.4209, Accuracy: 0.8187\n",
      "Epoch [20/25], Loss: 0.4179, Accuracy: 0.8251\n",
      "Epoch [20/25], Loss: 0.4179, Accuracy: 0.8251\n",
      "Epoch [25/25], Loss: 0.4142, Accuracy: 0.8264\n",
      "==================================================\n",
      "Training completed for Task 4!\n",
      "Model saved as 'saved_models/model-ann-11-8-8-8-1-pt.pth'\n",
      "\n",
      "============================================================\n",
      "TASK 4 MODEL PERFORMANCE ON TEST SET\n",
      "============================================================\n",
      "Accuracy:  0.8206 (82.06%)\n",
      "Precision: 0.6215 (62.15%)\n",
      "Recall:    0.3005 (30.05%)\n",
      "F1 Score:  0.4052 (40.52%)\n",
      "============================================================\n",
      "Epoch [25/25], Loss: 0.4142, Accuracy: 0.8264\n",
      "==================================================\n",
      "Training completed for Task 4!\n",
      "Model saved as 'saved_models/model-ann-11-8-8-8-1-pt.pth'\n",
      "\n",
      "============================================================\n",
      "TASK 4 MODEL PERFORMANCE ON TEST SET\n",
      "============================================================\n",
      "Accuracy:  0.8206 (82.06%)\n",
      "Precision: 0.6215 (62.15%)\n",
      "Recall:    0.3005 (30.05%)\n",
      "F1 Score:  0.4052 (40.52%)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Task 4: Neural network 11-8-8-8-1\n",
    "class ANN_11_8_8_8_1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ANN_11_8_8_8_1, self).__init__()\n",
    "        self.hidden1 = nn.Linear(11, 8)\n",
    "        self.hidden2 = nn.Linear(8, 8)\n",
    "        self.hidden3 = nn.Linear(8, 8)\n",
    "        self.output = nn.Linear(8, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.hidden1(x))\n",
    "        x = self.relu(self.hidden2(x))\n",
    "        x = self.relu(self.hidden3(x))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x\n",
    "\n",
    "model_11_8_8_8_1 = ANN_11_8_8_8_1()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model_11_8_8_8_1.parameters(), lr=0.001)\n",
    "\n",
    "print(\"Task 4 Model (11-8-8-8-1):\")\n",
    "print(f\"Parameters: {sum(p.numel() for p in model_11_8_8_8_1.parameters())}\")\n",
    "\n",
    "# Training\n",
    "epochs = 25\n",
    "print(\"Training Task 4...\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model_11_8_8_8_1.train()\n",
    "    epoch_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for data, targets in train_loader:\n",
    "        outputs = model_11_8_8_8_1(data)\n",
    "        loss = criterion(outputs.squeeze(), targets)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        predicted = (outputs.squeeze() > 0.5).float()\n",
    "        correct += (predicted == targets).sum().item()\n",
    "        total += targets.size(0)\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        avg_loss = epoch_loss / len(train_loader)\n",
    "        accuracy = correct / total\n",
    "        print(f\"Epoch {epoch+1}: Loss={avg_loss:.4f}, Acc={accuracy:.4f}\")\n",
    "\n",
    "torch.save(model_11_8_8_8_1.state_dict(), 'saved_models/model-ann-11-8-8-8-1-pt.pth')\n",
    "\n",
    "# Test\n",
    "model_11_8_8_8_1.eval()\n",
    "all_predictions_task4 = []\n",
    "all_targets_task4 = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, targets in test_loader:\n",
    "        outputs = model_11_8_8_8_1(data)\n",
    "        predictions = (outputs.squeeze() > 0.5).float()\n",
    "        all_predictions_task4.extend(predictions.cpu().numpy())\n",
    "        all_targets_task4.extend(targets.cpu().numpy())\n",
    "\n",
    "all_predictions_task4 = np.array(all_predictions_task4)\n",
    "all_targets_task4 = np.array(all_targets_task4)\n",
    "\n",
    "accuracy_task4 = accuracy_score(all_targets_task4, all_predictions_task4)\n",
    "precision_task4 = precision_score(all_targets_task4, all_predictions_task4)\n",
    "recall_task4 = recall_score(all_targets_task4, all_predictions_task4)\n",
    "f1_task4 = f1_score(all_targets_task4, all_predictions_task4)\n",
    "\n",
    "print(f\"\\nTask 4 Results:\")\n",
    "print(f\"Accuracy: {accuracy_task4:.4f}\")\n",
    "print(f\"F1 Score: {f1_task4:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: (10 points)\n",
    "\n",
    "* Again, repeat Task 3 with the following new architecture of the neural network:\n",
    "\n",
    "![Task 5 ANN architecture](figures/nn-3.png)\n",
    "\n",
    "* Input layer will still have 11 units as the dimension of training set (i.e, number of columns = 11).\n",
    "* Hidden-layer-1: 8 neurons, with relu activation\n",
    "* Hidden-layer-2: 4 neurons, with relu activation,\n",
    "* Hidden-layer-3: 2 neurons, with relu activation,\n",
    "* Output-layer: 1 neuron with sigmoid.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 5 - Model Architecture (11-8-4-2-1):\n",
      "ANN_11_8_4_2_1(\n",
      "  (hidden1): Linear(in_features=11, out_features=8, bias=True)\n",
      "  (hidden2): Linear(in_features=8, out_features=4, bias=True)\n",
      "  (hidden3): Linear(in_features=4, out_features=2, bias=True)\n",
      "  (output): Linear(in_features=2, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "\n",
      "Total parameters: 145\n",
      "\n",
      "Starting training for Task 5...\n",
      "==================================================\n",
      "Epoch [1/25], Loss: 0.5566, Accuracy: 0.7965\n",
      "Epoch [5/25], Loss: 0.4737, Accuracy: 0.8079\n",
      "Epoch [5/25], Loss: 0.4737, Accuracy: 0.8079\n",
      "Epoch [10/25], Loss: 0.4356, Accuracy: 0.8260\n",
      "Epoch [10/25], Loss: 0.4356, Accuracy: 0.8260\n",
      "Epoch [15/25], Loss: 0.4289, Accuracy: 0.8267\n",
      "Epoch [15/25], Loss: 0.4289, Accuracy: 0.8267\n",
      "Epoch [20/25], Loss: 0.4256, Accuracy: 0.8294\n",
      "Epoch [20/25], Loss: 0.4256, Accuracy: 0.8294\n",
      "Epoch [25/25], Loss: 0.4226, Accuracy: 0.8301\n",
      "==================================================\n",
      "Training completed for Task 5!\n",
      "Model saved as 'saved_models/model-ann-11-8-4-2-1-pt.pth'\n",
      "\n",
      "============================================================\n",
      "TASK 5 MODEL PERFORMANCE ON TEST SET\n",
      "============================================================\n",
      "Accuracy:  0.8172 (81.72%)\n",
      "Precision: 0.5894 (58.94%)\n",
      "Recall:    0.3333 (33.33%)\n",
      "F1 Score:  0.4258 (42.58%)\n",
      "============================================================\n",
      "\n",
      "================================================================================\n",
      "FINAL COMPARISON OF ALL THREE MODELS\n",
      "================================================================================\n",
      "Model Architecture | Accuracy | Precision | Recall | F1 Score | Parameters\n",
      "--------------------------------------------------------------------------------\n",
      "Task 3 (11-5-4-1)  | 0.8301   | 0.5542    | 0.2514 | 0.3459   |  89\n",
      "Task 4 (11-8-8-8-1)| 0.8206   | 0.6215    | 0.3005 | 0.4052   | 249\n",
      "Task 5 (11-8-4-2-1)| 0.8172   | 0.5894    | 0.3333 | 0.4258   | 145\n",
      "================================================================================\n",
      "\n",
      "Best performing model: Task 5 (11-8-4-2-1) with F1 Score: 0.4258\n",
      "HW 2 Deep Learning Assignment Completed Successfully! 🎉\n",
      "Epoch [25/25], Loss: 0.4226, Accuracy: 0.8301\n",
      "==================================================\n",
      "Training completed for Task 5!\n",
      "Model saved as 'saved_models/model-ann-11-8-4-2-1-pt.pth'\n",
      "\n",
      "============================================================\n",
      "TASK 5 MODEL PERFORMANCE ON TEST SET\n",
      "============================================================\n",
      "Accuracy:  0.8172 (81.72%)\n",
      "Precision: 0.5894 (58.94%)\n",
      "Recall:    0.3333 (33.33%)\n",
      "F1 Score:  0.4258 (42.58%)\n",
      "============================================================\n",
      "\n",
      "================================================================================\n",
      "FINAL COMPARISON OF ALL THREE MODELS\n",
      "================================================================================\n",
      "Model Architecture | Accuracy | Precision | Recall | F1 Score | Parameters\n",
      "--------------------------------------------------------------------------------\n",
      "Task 3 (11-5-4-1)  | 0.8301   | 0.5542    | 0.2514 | 0.3459   |  89\n",
      "Task 4 (11-8-8-8-1)| 0.8206   | 0.6215    | 0.3005 | 0.4052   | 249\n",
      "Task 5 (11-8-4-2-1)| 0.8172   | 0.5894    | 0.3333 | 0.4258   | 145\n",
      "================================================================================\n",
      "\n",
      "Best performing model: Task 5 (11-8-4-2-1) with F1 Score: 0.4258\n",
      "HW 2 Deep Learning Assignment Completed Successfully! 🎉\n"
     ]
    }
   ],
   "source": [
    "# Task 5: Neural network 11-8-4-2-1\n",
    "class ANN_11_8_4_2_1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ANN_11_8_4_2_1, self).__init__()\n",
    "        self.hidden1 = nn.Linear(11, 8)\n",
    "        self.hidden2 = nn.Linear(8, 4)\n",
    "        self.hidden3 = nn.Linear(4, 2)\n",
    "        self.output = nn.Linear(2, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.hidden1(x))\n",
    "        x = self.relu(self.hidden2(x))\n",
    "        x = self.relu(self.hidden3(x))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x\n",
    "\n",
    "model_11_8_4_2_1 = ANN_11_8_4_2_1()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model_11_8_4_2_1.parameters(), lr=0.001)\n",
    "\n",
    "print(\"Task 5 Model (11-8-4-2-1):\")\n",
    "print(f\"Parameters: {sum(p.numel() for p in model_11_8_4_2_1.parameters())}\")\n",
    "\n",
    "# Training\n",
    "epochs = 25\n",
    "print(\"Training Task 5...\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model_11_8_4_2_1.train()\n",
    "    epoch_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for data, targets in train_loader:\n",
    "        outputs = model_11_8_4_2_1(data)\n",
    "        loss = criterion(outputs.squeeze(), targets)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        predicted = (outputs.squeeze() > 0.5).float()\n",
    "        correct += (predicted == targets).sum().item()\n",
    "        total += targets.size(0)\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        avg_loss = epoch_loss / len(train_loader)\n",
    "        accuracy = correct / total\n",
    "        print(f\"Epoch {epoch+1}: Loss={avg_loss:.4f}, Acc={accuracy:.4f}\")\n",
    "\n",
    "torch.save(model_11_8_4_2_1.state_dict(), 'saved_models/model-ann-11-8-4-2-1-pt.pth')\n",
    "\n",
    "# Test\n",
    "model_11_8_4_2_1.eval()\n",
    "all_predictions_task5 = []\n",
    "all_targets_task5 = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, targets in test_loader:\n",
    "        outputs = model_11_8_4_2_1(data)\n",
    "        predictions = (outputs.squeeze() > 0.5).float()\n",
    "        all_predictions_task5.extend(predictions.cpu().numpy())\n",
    "        all_targets_task5.extend(targets.cpu().numpy())\n",
    "\n",
    "all_predictions_task5 = np.array(all_predictions_task5)\n",
    "all_targets_task5 = np.array(all_targets_task5)\n",
    "\n",
    "accuracy_task5 = accuracy_score(all_targets_task5, all_predictions_task5)\n",
    "precision_task5 = precision_score(all_targets_task5, all_predictions_task5)\n",
    "recall_task5 = recall_score(all_targets_task5, all_predictions_task5)\n",
    "f1_task5 = f1_score(all_targets_task5, all_predictions_task5)\n",
    "\n",
    "print(f\"\\nTask 5 Results:\")\n",
    "print(f\"Accuracy: {accuracy_task5:.4f}\")\n",
    "print(f\"F1 Score: {f1_task5:.4f}\")\n",
    "\n",
    "# Final comparison\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FINAL MODEL COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Task 3 (11-5-4-1):  Acc={accuracy:.4f}, F1={f1:.4f}\")\n",
    "print(f\"Task 4 (11-8-8-8-1): Acc={accuracy_task4:.4f}, F1={f1_task4:.4f}\")\n",
    "print(f\"Task 5 (11-8-4-2-1): Acc={accuracy_task5:.4f}, F1={f1_task5:.4f}\")\n",
    "\n",
    "best_f1 = max(f1, f1_task4, f1_task5)\n",
    "if best_f1 == f1:\n",
    "    best = \"Task 3\"\n",
    "elif best_f1 == f1_task4:\n",
    "    best = \"Task 4\"\n",
    "else:\n",
    "    best = \"Task 5\"\n",
    "\n",
    "print(f\"\\nBest model: {best} with F1={best_f1:.4f}\")\n",
    "print(\"Assignment complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# That's all folks! Thanks for your effort. \n",
    "\n",
    "Now, do the following to earn credit --\n",
    "\n",
    "0. Setting up:\n",
    "    - Make sure you actually experiment with this assignment. I would encourage (again) you to go through the possible compute resource you can use (e.g., Kaggle, Google Colab, etc.).\n",
    "    - It's always better to work in python virtual environment. Here are some resources for you to create and work in virtual environments [[win+mac+ubuntu](https://ashiskb.info/posts/2022/09/biswas/blog-1-python-venv/)][[windows+gpu](https://ashiskb.info/posts/2023/08/biswas/blog-win10-tensorflow/)][[ubuntu+gpu](https://ashiskb.info/posts/2023/08/biswas/blog-ubuntu-tensorflow/)]\n",
    "1. Please make sure to execute each cell in this jupyter notebook, and hit the 'Save' button, or go \"File > Save and Checkpoint\" menu option to save the notebook.\n",
    "2. Submit this notebook \"2025-Fall-DL-hw2.ipynb\" into Canvas \"hw-2\" entry. \n",
    "3. Done!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
